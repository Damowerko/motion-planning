{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# set theme\n",
    "sns.set_theme(\n",
    "    context=\"paper\",\n",
    "    style=\"whitegrid\",\n",
    "    rc={\n",
    "        \"figure.figsize\": (7.0, 3.5),\n",
    "        \"savefig.dpi\": 300,\n",
    "        \"figure.autolayout\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "fig_path = Path(\"../figures\")\n",
    "model = \"1zgs74or\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for policy_path in (fig_path / \"test_results\").iterdir():\n",
    "    if not policy_path.is_dir():\n",
    "        continue\n",
    "    if not model in policy_path.name:\n",
    "        continue\n",
    "    rewards = np.load(policy_path / \"rewards.npy\")\n",
    "    avgs = rewards.mean(axis=2)\n",
    "    n_trials, n_steps = avgs.shape\n",
    "    trial_idx, step_idx = np.mgrid[:n_trials, :n_steps]\n",
    "    dfs.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"experiment\": policy_path.name[len(model)+1:],\n",
    "                \"trial_idx\": trial_idx.flatten(),\n",
    "                \"step_idx\": step_idx.flatten(),\n",
    "                \"reward\": avgs.flatten(),\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "df = pd.concat(dfs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots (Constant Area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the line plot\n",
    "area_df = df[df[\"experiment\"].str[-1] == \"r\"]\n",
    "\n",
    "sns.lineplot(\n",
    "    data=area_df,\n",
    "    x=\"step_idx\",\n",
    "    y=\"reward\",\n",
    "    hue=\"experiment\",\n",
    "    errorbar=\"sd\",\n",
    ")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward Comparison (Constant Area)\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(fig_path / f\"{model}_transfer_area.png\")\n",
    "plt.savefig(fig_path / f\"{model}_transfer_area.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the comparison of final rewards\n",
    "area_final = area_df[area_df[\"step_idx\"] == 199]\n",
    "area_final[\"num_agents\"] = area_final[\"experiment\"].str[:-2].astype(int)\n",
    "area_final = area_final[[\"num_agents\", \"reward\"]].groupby([\"num_agents\"]).mean()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=area_final,\n",
    "    x=\"num_agents\",\n",
    "    y=\"reward\",\n",
    ")\n",
    "plt.xlabel(\"Number of Agents\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Final Reward Comparison (Constant Area)\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(fig_path / f\"{model}_transfer_area_final.png\")\n",
    "plt.savefig(fig_path / f\"{model}_transfer_area_final.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots (Constant Number of Agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the line plot\n",
    "agents_df = df[df[\"experiment\"].str[-1] == \"a\"]\n",
    "\n",
    "sns.lineplot(\n",
    "    data=agents_df,\n",
    "    x=\"step_idx\",\n",
    "    y=\"reward\",\n",
    "    hue=\"experiment\",\n",
    "    errorbar=\"sd\",\n",
    ")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward Comparison (Constant Number of Agents)\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(fig_path / f\"{model}_transfer_agents.png\")\n",
    "plt.savefig(fig_path / f\"{model}_transfer_agents.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the comparison of final rewards\n",
    "agents_final = agents_df[agents_df[\"step_idx\"] == 199]\n",
    "agents_final[\"width\"] = agents_final[\"experiment\"].str[:-2].astype(float)\n",
    "agents_final = agents_final[[\"width\", \"reward\"]].groupby([\"width\"]).mean()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=agents_final,\n",
    "    x=\"width\",\n",
    "    y=\"reward\",\n",
    ")\n",
    "plt.xlabel(\"Width of Field\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Final Reward Comparison (Constant Number of Agents)\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(fig_path / f\"{model}_transfer_agents_final.png\")\n",
    "plt.savefig(fig_path / f\"{model}_transfer_agents_final.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots (Constant Density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the line plot\n",
    "density_df = df[df[\"experiment\"].str[-1] == \"d\"]\n",
    "\n",
    "sns.lineplot(\n",
    "    data=density_df,\n",
    "    x=\"step_idx\",\n",
    "    y=\"reward\",\n",
    "    hue=\"experiment\",\n",
    "    errorbar=\"sd\",\n",
    ")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Reward Comparison (Constant Density)\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(fig_path / f\"{model}_transfer_density.png\")\n",
    "plt.savefig(fig_path / f\"{model}_transfer_density.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the comparison of final rewards\n",
    "density_final = density_df[density_df[\"step_idx\"] == 199]\n",
    "density_final[\"num_agents\"] = density_final[\"experiment\"].str[:-2].astype(int)\n",
    "density_final = density_final[[\"num_agents\", \"reward\"]].groupby([\"num_agents\"]).mean()\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=density_final,\n",
    "    x=\"num_agents\",\n",
    "    y=\"reward\",\n",
    ")\n",
    "plt.xlabel(\"Number of Agents\")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.title(\"Final Reward Comparison (Constant Density)\")\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(fig_path / f\"{model}_transfer_density_final.png\")\n",
    "plt.savefig(fig_path / f\"{model}_transfer_density_final.pdf\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "motion-planning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
